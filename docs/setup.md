# ç¯å¢ƒè®¾ç½®å’Œä¾èµ–é…ç½®æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¦‚ä½•ä¸ºè¶…åˆ†è¾¨ç‡ã€å»å™ªå’Œå›¾åƒä¿®å¤ä»»åŠ¡è®¾ç½®å®Œæ•´çš„å¼€å‘å’Œè¿è¡Œç¯å¢ƒã€‚

## ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### æœ€å°é…ç½®
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 18.04+ / Windows 10+ / macOS 10.15+
- **Python**: 3.7+
- **å†…å­˜**: 8GB RAM
- **å­˜å‚¨**: 20GB å¯ç”¨ç©ºé—´
- **GPU**: å¯é€‰ï¼Œä½†å¼ºçƒˆæ¨è

### æ¨èé…ç½®
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 LTS
- **Python**: 3.8-3.10
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 50GB+ SSD
- **GPU**: NVIDIA RTX 3080+ / Tesla V100+ (8GB+ VRAM)

## ğŸ Python ç¯å¢ƒè®¾ç½®

### 1. ä½¿ç”¨ Condaï¼ˆæ¨èï¼‰

```bash
# å®‰è£… Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n cv_tasks python=3.9
conda activate cv_tasks

# å®‰è£…åŸºç¡€åŒ…
conda install numpy scipy matplotlib pillow opencv
```

### 2. ä½¿ç”¨ virtualenv

```bash
# å®‰è£… virtualenv
pip install virtualenv

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv cv_env
source cv_env/bin/activate  # Linux/Mac
# cv_env\Scripts\activate    # Windows

# å‡çº§ pip
pip install --upgrade pip
```

## ğŸ“¦ ä¾èµ–åŒ…å®‰è£…

### æ ¸å¿ƒä¾èµ–æ–‡ä»¶ (`requirements.txt`)

```txt
# æ·±åº¦å­¦ä¹ æ¡†æ¶
torch>=1.12.0
torchvision>=0.13.0
torchaudio>=0.12.0

# å›¾åƒå¤„ç†
opencv-python>=4.6.0
Pillow>=9.0.0
scikit-image>=0.19.0
imageio>=2.19.0
albumentations>=1.2.0

# æ•°å€¼è®¡ç®—
numpy>=1.21.0
scipy>=1.7.0
matplotlib>=3.5.0

# é…ç½®å’Œå·¥å…·
PyYAML>=6.0
tqdm>=4.64.0
click>=8.0.0
colorama>=0.4.5

# è¯„ä¼°æŒ‡æ ‡
lpips>=0.1.4
pytorch-fid>=0.3.0
pyiqa>=0.1.7

# å¯è§†åŒ–å’Œæ—¥å¿—
tensorboard>=2.9.0
wandb>=0.12.0
seaborn>=0.11.0

# å®ç”¨å·¥å…·
h5py>=3.7.0
lmdb>=1.3.0
requests>=2.28.0
```

### GPU æ”¯æŒå®‰è£…

#### CUDA 11.8 (æ¨è)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### CUDA 11.7
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
```

#### ROCm (AMD GPU)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.4.2
```

#### MPS (Apple Silicon)
```bash
pip install torch torchvision torchaudio
```

### éªŒè¯GPUå®‰è£…

```python
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU count: {torch.cuda.device_count()}")
    print(f"GPU name: {torch.cuda.get_device_name(0)}")
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„è®¾ç½®

### åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p muyuliyan_cv && cd muyuliyan_cv

# åˆ›å»ºå­ç›®å½•
mkdir -p {config,models,data,src,logs,scripts,tools,tests,docs}
mkdir -p data/{input,output,train,val,test}
mkdir -p data/output/{super_resolution,denoising,inpainting}
mkdir -p models/{super_resolution,denoising,inpainting}
mkdir -p logs/{super_resolution,denoising,inpainting}

# åˆ›å»ºåˆå§‹æ–‡ä»¶
touch src/__init__.py
touch config/__init__.py
touch tools/__init__.py
```

### å®Œæ•´é¡¹ç›®ç»“æ„

```
muyuliyan_cv/
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ super_resolution_config.yaml
â”‚   â”œâ”€â”€ denoising_config.yaml
â”‚   â””â”€â”€ inpainting_config.yaml
â”œâ”€â”€ models/                     # é¢„è®­ç»ƒæ¨¡å‹
â”‚   â”œâ”€â”€ super_resolution/
â”‚   â”œâ”€â”€ denoising/
â”‚   â””â”€â”€ inpainting/
â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ input/                  # è¾“å…¥æ•°æ®
â”‚   â”œâ”€â”€ output/                 # è¾“å‡ºç»“æœ
â”‚   â”œâ”€â”€ train/                  # è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ val/                    # éªŒè¯æ•°æ®
â”‚   â””â”€â”€ test/                   # æµ‹è¯•æ•°æ®
â”œâ”€â”€ src/                        # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ super_resolution.py
â”‚   â”œâ”€â”€ denoising.py
â”‚   â”œâ”€â”€ inpainting.py
â”‚   â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ metrics/                # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ scripts/                    # è„šæœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ download_models.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â””â”€â”€ evaluate_models.py
â”œâ”€â”€ tools/                      # å·¥å…·ç¨‹åº
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ benchmarking.py
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## âš™ï¸ ç¯å¢ƒé…ç½®æ–‡ä»¶

### 1. å¼€å‘ç¯å¢ƒé…ç½® (`environment.yml`)

```yaml
name: cv_tasks
channels:
  - pytorch
  - conda-forge
  - defaults
dependencies:
  - python=3.9
  - numpy=1.21
  - scipy=1.7
  - matplotlib=3.5
  - pillow=9.0
  - opencv=4.6
  - pytorch=1.12
  - torchvision=0.13
  - torchaudio=0.12
  - cudatoolkit=11.8  # å¦‚æœä½¿ç”¨GPU
  - pip
  - pip:
    - lpips>=0.1.4
    - pytorch-fid>=0.3.0
    - albumentations>=1.2.0
    - wandb>=0.12.0
    - pyiqa>=0.1.7
```

ä½¿ç”¨ Conda åˆ›å»ºç¯å¢ƒï¼š
```bash
conda env create -f environment.yml
conda activate cv_tasks
```

### 2. Docker é…ç½® (`Dockerfile`)

```dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /workspace

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# å®‰è£…PyTorch with CUDA
RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# è®¾ç½®Pythonè·¯å¾„
ENV PYTHONPATH=/workspace

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦webæœåŠ¡ï¼‰
EXPOSE 8080

# é»˜è®¤å‘½ä»¤
CMD ["bash"]
```

Docker ä½¿ç”¨å‘½ä»¤ï¼š
```bash
# æ„å»ºé•œåƒ
docker build -t cv_tasks:latest .

# è¿è¡Œå®¹å™¨
docker run --gpus all -it --rm \
    -v $(pwd):/workspace \
    -p 8080:8080 \
    cv_tasks:latest
```

### 3. VS Code é…ç½® (`.vscode/settings.json`)

```json
{
    "python.defaultInterpreterPath": "./cv_env/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length=88"],
    "python.sortImports.args": ["--profile", "black"],
    "files.associations": {
        "*.yaml": "yaml",
        "*.yml": "yaml"
    },
    "yaml.schemas": {
        "./config/schema.json": ["config/*.yaml", "config/*.yml"]
    },
    "editor.rulers": [88],
    "editor.formatOnSave": true
}
```

## ğŸ”§ å¼€å‘å·¥å…·é…ç½®

### 1. ä»£ç æ ¼å¼åŒ– (`.pre-commit-config.yaml`)

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        
  - repo: https://github.com/psf/black
    rev: 22.10.0
    hooks:
      - id: black
        language_version: python3
        
  - repo: https://github.com/pycqa/isort
    rev: 5.10.1
    hooks:
      - id: isort
        args: ["--profile", "black"]
        
  - repo: https://github.com/pycqa/flake8
    rev: 5.0.4
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203]
```

å®‰è£…å’Œä½¿ç”¨ï¼š
```bash
pip install pre-commit
pre-commit install
pre-commit run --all-files
```

### 2. æµ‹è¯•é…ç½® (`pytest.ini`)

```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --strict-markers
    --disable-warnings
    --cov=src
    --cov-report=html
    --cov-report=term-missing
markers =
    slow: marks tests as slow
    gpu: marks tests as requiring GPU
    integration: marks tests as integration tests
```

### 3. æ€§èƒ½åˆ†æé…ç½®

```python
# profiling_config.py
import cProfile
import pstats
from functools import wraps

def profile_function(func):
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        pr = cProfile.Profile()
        pr.enable()
        result = func(*args, **kwargs)
        pr.disable()
        
        stats = pstats.Stats(pr)
        stats.sort_stats('cumulative')
        stats.print_stats(20)  # æ˜¾ç¤ºå‰20ä¸ªæœ€è€—æ—¶çš„å‡½æ•°
        
        return result
    return wrapper
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—é…ç½®

### 1. æ—¥å¿—é…ç½® (`logging_config.yaml`)

```yaml
version: 1
formatters:
  default:
    format: '[%(asctime)s] %(levelname)s in %(module)s: %(message)s'
    datefmt: '%Y-%m-%d %H:%M:%S'
  detailed:
    format: '[%(asctime)s] %(levelname)s [%(name)s:%(lineno)d] %(message)s'
    datefmt: '%Y-%m-%d %H:%M:%S'

handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: default
    stream: ext://sys.stdout
    
  file:
    class: logging.handlers.RotatingFileHandler
    level: DEBUG
    formatter: detailed
    filename: logs/app.log
    maxBytes: 10485760  # 10MB
    backupCount: 5
    
  error_file:
    class: logging.handlers.RotatingFileHandler
    level: ERROR
    formatter: detailed
    filename: logs/error.log
    maxBytes: 10485760
    backupCount: 5

loggers:
  '':
    level: DEBUG
    handlers: [console, file, error_file]
    propagate: no
    
  src:
    level: DEBUG
    handlers: [console, file]
    propagate: no
```

### 2. W&B (Weights & Biases) é…ç½®

```python
# wandb_config.py
import wandb

def init_wandb(config, project_name="cv_tasks"):
    """åˆå§‹åŒ–W&Bæ—¥å¿—"""
    wandb.init(
        project=project_name,
        config=config,
        name=f"{config['task']}_{config['model']['name']}",
        tags=[config['task'], config['model']['name']],
        notes=config.get('description', ''),
        save_code=True
    )
    
    # ç›‘æ§GPUä½¿ç”¨ç‡
    wandb.config.update({
        "gpu_count": torch.cuda.device_count(),
        "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU"
    })

def log_metrics(metrics, step=None):
    """è®°å½•æŒ‡æ ‡"""
    wandb.log(metrics, step=step)

def log_images(images, caption="Results", step=None):
    """è®°å½•å›¾åƒ"""
    wandb.log({"images": [wandb.Image(img, caption=caption) for img in images]}, step=step)
```

## ğŸš€ è‡ªåŠ¨åŒ–è„šæœ¬

### 1. ç¯å¢ƒå®‰è£…è„šæœ¬ (`setup.sh`)

```bash
#!/bin/bash

set -e

echo "Setting up CV Tasks environment..."

# æ£€æŸ¥Pythonç‰ˆæœ¬
python_version=$(python3 --version 2>&1 | awk '{print $2}' | cut -d. -f1,2)
required_version="3.7"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" != "$required_version" ]; then
    echo "Error: Python $required_version or higher is required. Found: $python_version"
    exit 1
fi

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "Creating virtual environment..."
python3 -m venv cv_env
source cv_env/bin/activate

# å‡çº§pip
echo "Upgrading pip..."
pip install --upgrade pip

# å®‰è£…ä¾èµ–
echo "Installing dependencies..."
pip install -r requirements.txt

# æ£€æŸ¥GPUæ”¯æŒ
echo "Checking GPU support..."
python3 -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'GPU count: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
"

# åˆ›å»ºå¿…è¦ç›®å½•
echo "Creating project directories..."
mkdir -p data/{input,output,train,val,test}
mkdir -p data/output/{super_resolution,denoising,inpainting}
mkdir -p models/{super_resolution,denoising,inpainting}
mkdir -p logs/{super_resolution,denoising,inpainting}

# ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆå¯é€‰ï¼‰
echo "Do you want to download pre-trained models? (y/n)"
read -r download_models
if [ "$download_models" = "y" ]; then
    echo "Downloading models..."
    python3 scripts/download_models.py
fi

echo "Setup completed successfully!"
echo "To activate the environment, run: source cv_env/bin/activate"
```

### 2. æ¨¡å‹ä¸‹è½½è„šæœ¬ (`scripts/download_models.py`)

```python
import os
import sys
import requests
from tqdm import tqdm
import hashlib

def download_file(url, filename, expected_hash=None):
    """ä¸‹è½½æ–‡ä»¶å¹¶éªŒè¯hash"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(filename):
        if expected_hash:
            with open(filename, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            if file_hash == expected_hash:
                print(f"File {filename} already exists and is valid.")
                return
    
    print(f"Downloading {filename}...")
    
    response = requests.get(url, stream=True)
    response.raise_for_status()
    
    total_size = int(response.headers.get('content-length', 0))
    
    with open(filename, 'wb') as f, tqdm(
        desc=os.path.basename(filename),
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                pbar.update(len(chunk))
    
    # éªŒè¯æ–‡ä»¶hash
    if expected_hash:
        with open(filename, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        if file_hash != expected_hash:
            print(f"Warning: Hash mismatch for {filename}")
            return False
    
    print(f"Successfully downloaded {filename}")
    return True

def main():
    """ä¸‹è½½æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹"""
    models = {
        # è¶…åˆ†è¾¨ç‡æ¨¡å‹
        "models/super_resolution/esrgan_x4.pth": {
            "url": "https://github.com/xinntao/ESRGAN/releases/download/v0.0.0/RRDB_ESRGAN_x4.pth",
            "hash": "aa0d6e2d7e6e6c7c5a5c5e5e5e5e5e5e"
        },
        
        # å»å™ªæ¨¡å‹
        "models/denoising/dncnn_25.pth": {
            "url": "https://github.com/cszn/DnCNN/releases/download/v0.0.0/dncnn_25.pth",
            "hash": "bb0d6e2d7e6e6c7c5a5c5e5e5e5e5e5e"
        },
        
        # å›¾åƒä¿®å¤æ¨¡å‹
        "models/inpainting/lama_model.pth": {
            "url": "https://github.com/saic-mdal/lama/releases/download/v1.0.0/lama_model.pth",
            "hash": "cc0d6e2d7e6e6c7c5a5c5e5e5e5e5e5e"
        }
    }
    
    print("Downloading pre-trained models...")
    
    success_count = 0
    total_count = len(models)
    
    for filename, info in models.items():
        try:
            if download_file(info["url"], filename, info.get("hash")):
                success_count += 1
        except Exception as e:
            print(f"Failed to download {filename}: {str(e)}")
    
    print(f"\nDownload completed: {success_count}/{total_count} successful")
    
    if success_count < total_count:
        print("Some models failed to download. You can manually download them later.")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### 1. CUDA ç‰ˆæœ¬ä¸åŒ¹é…
```bash
# é—®é¢˜ï¼šCUDAç‰ˆæœ¬ä¸PyTorchä¸å…¼å®¹
# è§£å†³æ–¹æ¡ˆï¼šé‡æ–°å®‰è£…åŒ¹é…çš„PyTorchç‰ˆæœ¬
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 2. å†…å­˜ä¸è¶³
```bash
# é—®é¢˜ï¼šGPUå†…å­˜ä¸è¶³
# è§£å†³æ–¹æ¡ˆï¼šå‡å°batch sizeæˆ–ä½¿ç”¨CPU
export CUDA_VISIBLE_DEVICES=""  # å¼ºåˆ¶ä½¿ç”¨CPU
```

#### 3. ä¾èµ–åŒ…å†²çª
```bash
# é—®é¢˜ï¼šåŒ…ç‰ˆæœ¬å†²çª
# è§£å†³æ–¹æ¡ˆï¼šåˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
conda create -n cv_tasks_new python=3.9
conda activate cv_tasks_new
pip install -r requirements.txt
```

#### 4. æ¨¡å‹åŠ è½½å¤±è´¥
```python
# é—®é¢˜ï¼šæ¨¡å‹æƒé‡ä¸åŒ¹é…
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨strict=FalseåŠ è½½
model.load_state_dict(torch.load(model_path), strict=False)
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨SSDå­˜å‚¨**: æ•°æ®è¯»å†™å¯†é›†æ—¶ä½¿ç”¨SSD
2. **æ•°æ®é¢„å¤„ç†**: ä½¿ç”¨å¤šè¿›ç¨‹é¢„å¤„ç†æ•°æ®
3. **å†…å­˜ç®¡ç†**: å®šæœŸæ¸…ç†GPUç¼“å­˜
4. **æ‰¹å¤„ç†**: åˆç†è®¾ç½®batch size
5. **æ··åˆç²¾åº¦**: ä½¿ç”¨FP16å‡å°‘å†…å­˜ä½¿ç”¨

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# ~/.bashrc æˆ– ~/.zshrc
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# è®¾ç½®OpenCVä½¿ç”¨çš„çº¿ç¨‹æ•°
export OMP_NUM_THREADS=4

# è®¾ç½®PyTorchä½¿ç”¨çš„çº¿ç¨‹æ•°
export MKL_NUM_THREADS=4

# ç¦ç”¨TensorFlowè­¦å‘Š
export TF_CPP_MIN_LOG_LEVEL=2
```

---

**æç¤º**: ç¯å¢ƒé…ç½®æ˜¯é¡¹ç›®æˆåŠŸçš„åŸºç¡€ï¼Œå»ºè®®æŒ‰ç…§æœ¬æŒ‡å—é€æ­¥è®¾ç½®å¹¶æµ‹è¯•æ¯ä¸ªç¯èŠ‚ã€‚å¦‚é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿè¦æ±‚å’Œä¾èµ–ç‰ˆæœ¬æ˜¯å¦åŒ¹é…ã€‚